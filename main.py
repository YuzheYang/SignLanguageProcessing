import pandas as pdimport numpy as npimport matplotlib.pyplot as pltfrom keras.utils import np_utilsfrom tensorflow.keras.layers import *from tensorflow.keras import Modelfrom tensorflow.keras.preprocessing.image import ImageDataGeneratorfrom tensorflow.keras.callbacks import ReduceLROnPlateaufrom tensorflow.keras.optimizers import SGD, Adamdef normalization(data):    _range = np.max(data) - np.min(data)    return (data - np.min(data)) / _rangetrain_csv_file = r'F:\SignLanguage\sign_mnist_train.csv'all_train_data = pd.read_csv(train_csv_file)x_train = all_train_data.values[:, 1:].astype('float').reshape(-1, 28, 28, 1)x_train = normalization(x_train)y_train = all_train_data.values[:, 0].reshape(-1, 1)y_train = np_utils.to_categorical(y_train)test_csv_file = r'F:\SignLanguage\sign_mnist_test.csv'all_test_data = pd.read_csv(test_csv_file)x_test = all_test_data.values[:, 1:].astype('float').reshape(-1, 28, 28, 1)x_test = normalization(x_test)y_test = all_test_data.values[:, 0].reshape(-1, 1)y_test = np_utils.to_categorical(y_test)datagen = ImageDataGenerator(        featurewise_center=False,  # set input mean to 0 over the dataset        samplewise_center=False,  # set each sample mean to 0        featurewise_std_normalization=False,  # divide inputs by std of the dataset        samplewise_std_normalization=False,  # divide each input by its std        zca_whitening=False,  # apply ZCA whitening        rotation_range=10,  # randomly rotate images in the range (degrees, 0 to 180)        zoom_range = 0.1, # Randomly zoom image        width_shift_range=0.1,  # randomly shift images horizontally (fraction of total width)        height_shift_range=0.1,  # randomly shift images vertically (fraction of total height)        horizontal_flip=False,  # randomly flip images        vertical_flip=False)  # randomly flip imagesdatagen.fit(x_train)shape_inputdata = [28, 28, 1]input_data = Input(shape_inputdata)x = Conv2D(filters=64, kernel_size=3, activation='relu',padding='same')(input_data)x = BatchNormalization()(x)x = MaxPooling2D()(x)x = Conv2D(filters=128, kernel_size=3, activation='relu',padding='same')(x)x = BatchNormalization()(x)x = Conv2D(filters=128, kernel_size=3, activation='relu',padding='same')(x)x = MaxPooling2D()(x)x = Flatten()(x)x = Dense(512, activation='relu')(x)x = Dropout(0.3)(x)x = Dense(25, activation='softmax')(x)model = Model(input_data, x)# opt = SGD(lr=0.01, momentum=0.9, clipnorm=1.0)opt = Adam(learning_rate = 0.001)model.compile(loss='categorical_crossentropy', optimizer=opt, metrics=['categorical_accuracy'])learning_rate_reduction = ReduceLROnPlateau(monitor='val_categorical_accuracy',                                            patience = 2,                                            verbose=1,                                            factor=0.5,                                            min_lr=0.00001)history = model.fit(datagen.flow(x_train, y_train, batch_size=128), epochs=30, verbose=1,                    validation_data=(x_test, y_test), callbacks=[learning_rate_reduction])score = model.evaluate(x_test, y_test, verbose=0)model.save('LeNet5-SignLanguage.h5')plt.figure()plt.plot(history.history['categorical_accuracy'])plt.plot(history.history['val_categorical_accuracy'])plt.title('Model accuracy')plt.ylabel('Accuracy')plt.xlabel('Epoch')plt.legend(['Train', 'Test'], loc='upper left')plt.savefig('Acc.png')plt.figure()# 绘制训练 & 验证的损失值plt.plot(history.history['loss'])plt.plot(history.history['val_loss'])plt.title('Model loss')plt.ylabel('Loss')plt.xlabel('Epoch')plt.legend(['Train', 'Test'], loc='upper left')plt.savefig('Loss.png')